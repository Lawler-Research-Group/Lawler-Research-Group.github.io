<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> AI: Assistant First, Researcher Second | Lawler Research Group </title> <meta name="author" content="Michael J. Lawler"> <meta name="description" content="by Tristan Galler"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;L&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://lawlergroup.lassp.cornell.edu/blog/2025/AI-Assistant-First-Researcher-Second/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Lawler Research Group </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">People </a> </li> <li class="nav-item "> <a class="nav-link" href="/research/">Research </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">AI: Assistant First, Researcher Second</h1> <p class="post-meta"> Created in January 21, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/neuralnets"> <i class="fa-solid fa-hashtag fa-sm"></i> neuralnets</a>   <a href="/blog/tag/materials-science"> <i class="fa-solid fa-hashtag fa-sm"></i> materials science</a>   <a href="/blog/tag/rag"> <i class="fa-solid fa-hashtag fa-sm"></i> RAG</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Four months ago, I embarked on an ambitious experiment: I wanted to prompt-engineer ChatGPT-3 into constructing a variance matrix from data of multiple Ising models, ultimately allowing it to generate its own Ising model based on the collected data. This task, which seemed plausible given the growing capabilities of AI, quickly illuminated the limitations of large language models (LLMs) in high-level scientific reasoning and computation. Despite its fluency and broad knowledge base, GPT-3 struggled with rigorous, mathematically intensive tasks that required deep reasoning and autonomous problem-solving. This realization, coupled with discussions with my mentor, spurred an ongoing inquiry: To what extent can foundational LLMs (large dataset AI such as ChatGPT or Llama) be fine-tuned for scientific research, particularly in condensed matter theory?</p> <h3 id="the-challenge-of-fine-tuning-llms-for-science">The Challenge of Fine-Tuning LLMs for Science</h3> <p>While fine-tuning LLMs for domain-specific expertise is a promising approach, the availability of well-trained scientific models remains limited. The closest counterpart I found was <a href="https://arxiv.org/abs/2404.08001" rel="external nofollow noopener" target="_blank">Xiwu</a> [1], a recently developed L2 (fine-tuned from a foundational model) LLM for high-energy physics. However, the landscape for condensed matter physics was sparse, and much of our data—such as scanning tunneling microscopy (STM) images—was more efficiently stored as images rather than text. Given these constraints, my mentor and I decided to pivot towards evaluating multimodal LLMs (MLLMs), particularly image-based models, to determine their efficacy in scientific analysis.</p> <h3 id="the-role-of-multimodal-llms">The Role of Multimodal LLMs</h3> <p>I have experience running LLMs locally, primarily using Llama models, which have evolved significantly from Llama2 to the contemporary Llama3.3. Historically, deploying and fine-tuning these models locally has been a cumbersome process, requiring different installation methods and optimization strategies depending on the specific model. However, the release of <a href="https://ollama.com/" rel="external nofollow noopener" target="_blank">Ollama</a>—a streamlined platform for running LLMs and MLLMs—greatly simplified this workflow. In the past two months, Ollama has expanded to support a diverse range of MLLMs, while also providing tools for UI development, API integration, and parameter management.</p> <p>To evaluate the capabilities of these MLLMs, I ran five different models using raw STM data from various materials, such as graphene. The largest model I tested, Llama3.2 Vision (11 billion-parameter model), demonstrated an impressive ability to recognize the general context of the images, even making reasonable predictions about the material composition and possible defects. However, all other models exhibited severe hallucinations, misidentifying the STM images as blankets or cloths.</p> <p align="center"> <img src="https://i.imgur.com/Y8KMmkY.jpeg" width="500"> </p> <p align="center"> <b>Fig. 1 An example of STM data sent to the LLMs, the material here being graphite [2].</b> </p> <h3 id="the-impact-of-prompt-engineering">The Impact of Prompt Engineering</h3> <p>In an attempt to first refine the models’ performance without adding new data, I implemented a simple yet effective intervention: prompt engineering. By adding a subtext to each prompt (essentially instructing the models to assume the role of a distinguished professor in condensed matter physics) I observed a dramatic improvement in their responses. Now, all five models correctly identified the STM technique and provided coherent analyses of material defects. However, this approach had a crucial limitation: it did not enhance the models’ ability to generate figures or perform rigorous quantitative analysis. Rather, it merely refocused their responses toward condensed matter physics without deepening their computational reasoning.</p> <p align="center"> <img src="https://i.imgur.com/qh0kYN3.png" width="80%"> </p> <p align="center"> <img src="https://i.imgur.com/ABVdcdy.png" width="80%"> </p> <p align="center"> <b>Figs. 2,3 The prompt engineered modification of Llava, a moderately large model, answering without hallucination.</b> </p> <h3 id="exploring-retrieval-augmented-generation">Exploring Retrieval-Augmented Generation</h3> <p>Recognizing that additional data might be required, I turned to Retrieval-Augmented Generation (RAG), a technique that embeds external data into the model’s vector space, allowing it to better match prompts with relevant information. However, even when embedding the papers that contained the images I uploaded, there was no improvement in recognition or scientific reasoning. In fact, without prompt engineering, the smaller models continued to hallucinate no matter the parameter of attention I put on the papers within the LLM.</p> <h3 id="gpt-4-the-standout-in-multimodal-reasoning">GPT-4: The Standout in Multimodal Reasoning</h3> <p>Despite my focus on open-source solutions, I have also been experimenting with GPT-4, which supports multimodal capabilities. Unlike the other models I tested, GPT-4 has shown remarkable proficiency in analyzing images, even providing annotated feedback on STM data. It remains the only model capable of returning modified images, highlighting possible defects for example, rather than just describing them in text. Furthermore, GPT-4 has demonstrated greater flexibility in fine-tuning, offering a glimpse into the potential of well-optimized multimodal AI for scientific research.</p> <p align="center"> <img src="https://i.imgur.com/FPioA8f.png" width="500"> </p> <p align="center"> <b>Fig. 4 GPT-4's impressive ability to communicate ideas through modifying uploaded images, evidenced by the red circles indicating possible defects.</b> </p> <h3 id="the-future-of-ai-in-scientific-research">The Future of AI in Scientific Research</h3> <p>These findings reinforce a key takeaway: while AI excels as a personalized assistant—summarizing papers, structuring research plans, and even contextualizing complex scientific ideas—it still falls short as an autonomous scientific researcher. The ability to engage in high-level reasoning, generate rigorous mathematical models, and independently conduct research on a local level remains beyond the reach of current LLMs and MLLMs, even with fine-tuning and retrieval techniques.</p> <p>However, the rapid evolution of AI suggests that these gaps may narrow in the coming years. With better fine-tuning techniques, accessible multimodal embedding programs, and more robust open-source research models, AI could eventually transition from a highly capable assistant to a legitimate collaborator in scientific discovery. Until then, researchers must leverage AI for what it currently does best—enhancing efficiency, improving accessibility, and accelerating preliminary analysis—while acknowledging its limitations in deep scientific reasoning.</p> <p>In the meantime, my next steps involve further experiments with RAG implementations, exploring alternative fine-tuning methods, and closely monitoring advancements in MLLMs. Whether through open-source models or proprietary solutions like GPT-4, the potential of AI in condensed matter physics remains an exciting frontier, albeit one that still requires significant human expertise to navigate effectively.</p> <p>[1]Zhang, Zhengde, et al. “Xiwu: A Basis Flexible and Learnable LLM for High Energy Physics”, arXiv:2404.08001, arXiv, 8 Apr. 2024. arXiv.org, https://doi.org/10.48550/arXiv.2404.08001.</p> <p>[2]“Capillary Force-Induced Superlattice Variation atop a Nanometer-Wide Graphene Flake and Its Moiré Origin Studied by STM.” Beilstein Journal of Nanotechnology, vol. 10, Jan. 2019, pp. 804–10. www.sciencedirect.com, https://doi.org/10.3762/bjnano.10.80.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/Grover's-algorithm-Blog-Post/">Grover dynamics for speeding up optimization</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/The_Relativistic_Quantum_Information_FAQ/">The Relativistic Quantum Information FAQ</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/Predicting_properties_of_metal_organic_frameworks/">Generating 2D Fingerprints to Predict Properties of Metal Organic Frameworks Using Machine Learning</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/Quantum_channel/">Introduction to information channels</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2021/Do-quantum-circuits-outperform-neural-networks/">Do Quantum Circuits Outperform Neural Networks?</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Michael J. Lawler. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: May 13, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-people",title:"People",description:"",section:"Navigation",handler:()=>{window.location.href="/people/"}},{id:"nav-research",title:"Research",description:"",section:"Navigation",handler:()=>{window.location.href="/research/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-repositories",title:"repositories",description:"Edit the `_data/repositories.yml` and change the `github_users` and `github_repos` lists to include your own GitHub profile and repositories.",section:"Navigation",handler:()=>{window.location.href="/repositories/"}},{id:"post-grover-dynamics-for-speeding-up-optimization",title:"Grover dynamics for speeding up optimization",description:"by Kevin Lee",section:"Posts",handler:()=>{window.location.href="/blog/2025/Grover's-algorithm-Blog-Post/"}},{id:"post-ai-assistant-first-researcher-second",title:"AI: Assistant First, Researcher Second",description:"by Tristan Galler",section:"Posts",handler:()=>{window.location.href="/blog/2025/AI-Assistant-First-Researcher-Second/"}},{id:"post-the-relativistic-quantum-information-faq",title:"The Relativistic Quantum Information FAQ",description:"by Eric Aspling",section:"Posts",handler:()=>{window.location.href="/blog/2022/The_Relativistic_Quantum_Information_FAQ/"}},{id:"post-generating-2d-fingerprints-to-predict-properties-of-metal-organic-frameworks-using-machine-learning",title:"Generating 2D Fingerprints to Predict Properties of Metal Organic Frameworks Using Machine Learning...",description:"by Jacob Barkovitch",section:"Posts",handler:()=>{window.location.href="/blog/2022/Predicting_properties_of_metal_organic_frameworks/"}},{id:"post-introduction-to-information-channels",title:"Introduction to information channels",description:"by Eric Aspling",section:"Posts",handler:()=>{window.location.href="/blog/2022/Quantum_channel/"}},{id:"post-do-quantum-circuits-outperform-neural-networks",title:"Do Quantum Circuits Outperform Neural Networks?",description:"by Michael Lawler",section:"Posts",handler:()=>{window.location.href="/blog/2021/Do-quantum-circuits-outperform-neural-networks/"}},{id:"post-the-art-of-quantum",title:"The art of quantum",description:"by Michael Lawler",section:"Posts",handler:()=>{window.location.href="/blog/2020/Why_think_quantum.md/"}},{id:"news-a-simple-inline-announcement",title:"A simple inline announcement.",description:"",section:"News"},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",title:'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"news-hot-off-the-press-topology-in-nonlinear-mechanical-systems-https-journals-aps-org-prl-abstract-10-1103-physrevlett-127-076802",title:"Hot off the press: [Topology in Nonlinear Mechanical Systems](https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.127.076802)",description:"",section:"News"},{id:"news-our-results-on-adaptive-variational-fermi-hubbard-circuits-https-journals-aps-org-pra-abstract-10-1103-physreva-105-012413-published-on-pra",title:"Our results on [adaptive variational Fermi-Hubbard circuits](https://journals.aps.org/pra/abstract/10.1103/PhysRevA.105.012413) published on PRA.",description:"",section:"News"},{id:"news-our-binghamton-graduate-student-eric-aspling-presented-a-poster-site-url-assets-pdf-qip2022sweden-pdf-at-quantum-information-and-probability-2022-conference-at-linnaeus-university-in-v\xe4xj\xf6-sweden",title:"Our Binghamton graduate student Eric Aspling presented a [poster]({{ site.url }}/assets/pdf/QIP2022Sweden.pdf) at Quantum...",description:"",section:"News"},{id:"news-po-wei-b-exam-topology-shared-between-classical-and-quantum-materials-site-url-assets-pdf-po-wei-bexam-pdf-701-clark-hall-or-zoom",title:"Po-Wei B Exam: [Topology Shared Between Classical and Quantum Materials]({{ site.url }}/assets/pdf/Po-Wei_Bexam.pdf) 701...",description:"",section:"News"},{id:"news-our-cornell-phd-student-po-wei-successfully-defended-his-thesis-congratulations-dr-lo",title:"Our Cornell PhD student Po-Wei successfully defended his thesis! Congratulations Dr. Lo!!!",description:"",section:"News"},{id:"news-arxiv-alert-that-is-3-in-a-day-phew-supersymmetry-on-the-lattice-geometry-topology-and-spin-liquids-https-arxiv-org-abs-2207-09475-the-fate-of-topological-frustration-in-quantum-spin-ladders-and-generalizations-https-arxiv-org-abs-2207-09549-topology-shared-between-classical-metamaterials-and-interacting-superconductors-https-arxiv-org-abs-2207-10045",title:"Arxiv alert: That is 3 in a day. Phew! [Supersymmetry on the lattice:...",description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%6D%6C%61%77%6C%65%72@%62%69%6E%67%68%61%6D%74%6F%6E.%65%64%75","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=QNcunFcAAAAJ","_blank")}},{id:"socials-researchgate",title:"ResearchGate",section:"Socials",handler:()=>{window.open("https://www.researchgate.net/profile/Michael-Lawler/","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>